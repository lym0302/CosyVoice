# Copyright (c) 2024 Alibaba Inc (authors: Xiang Lyu, Zhihao Du)
#               2025 Alibaba Inc (authors: Xiang Lyu, Yabin Li, Qihua)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Optional, List, Dict, Callable, Generator
from transformers import Qwen2ForCausalLM
import math

from cosyvoice.llm.llm import Qwen2LM
from cosyvoice.snn.modules import mem_update_MSF
from cosyvoice.utils.mask import make_pad_mask
from cosyvoice.utils.common import th_accuracy, IGNORE_ID


class SNNAdapter(nn.Module):
    """SNNé€‚é…å™¨ - åœ¨ä¸ä¿®æ”¹åŸå§‹Transformerç»“æ„çš„æƒ…å†µä¸‹å¢åŠ SNNåŠŸèƒ½"""
    
    def __init__(self, hidden_size, msf_config=None):
        super().__init__()
        self.hidden_size = hidden_size
        
        # MSF SNNç»„ä»¶
        msf_config = msf_config or {}
        self.snn_processor = mem_update_MSF(
            decay=msf_config.get('decay', 0.25),
            init_thre=msf_config.get('init_thre', 1.0),
            D=msf_config.get('D', 4),
            surro_gate=msf_config.get('surro_gate', 'rectangular')
        )
        
        # å¯å­¦ä¹ çš„èåˆæƒé‡
        self.alpha = nn.Parameter(torch.tensor(0.1))  # åˆå§‹æ—¶SNNå½±å“å¾ˆå°
        
        # å¯é€‰çš„æŠ•å½±å±‚ï¼Œä¿æŒç»´åº¦ä¸€è‡´
        self.use_projection = msf_config.get('use_projection', False)
        if self.use_projection:
            self.proj_in = nn.Linear(hidden_size, hidden_size)
            self.proj_out = nn.Linear(hidden_size, hidden_size)
    
    def forward(self, x):
        """
        x: [batch, seq_len, hidden_size]
        è¿”å›: SNNå¢å¼ºåçš„ç‰¹å¾
        """
        batch_size, seq_len, hidden_size = x.shape
        
        # å¯é€‰çš„è¾“å…¥æŠ•å½±
        if self.use_projection:
            x_proj = self.proj_in(x)
        else:
            x_proj = x
        
        # MSFå¤„ç†ï¼šéœ€è¦ [time_window, batch, features] æ ¼å¼
        snn_input = x_proj.permute(1, 0, 2)  # [seq_len, batch, hidden_size]
        snn_output = self.snn_processor(snn_input)  # MSFå¤„ç†
        snn_output = snn_output.permute(1, 0, 2)  # è½¬å› [batch, seq_len, hidden_size]
        
        # å¯é€‰çš„è¾“å‡ºæŠ•å½±
        if self.use_projection:
            snn_output = self.proj_out(snn_output)
        
        # è‡ªé€‚åº”èåˆï¼šåŸå§‹ç‰¹å¾ + alpha * SNNç‰¹å¾
        enhanced_output = x + self.alpha * snn_output
        
        return enhanced_output


class Qwen2Encoder_SNN(nn.Module):
    """
    ä¿æŒé¢„è®­ç»ƒæƒé‡å…¼å®¹çš„SNNå¢å¼ºQwen2ç¼–ç å™¨
    ç­–ç•¥ï¼šåœ¨åŸå§‹Transformerå±‚ä¹‹åæ’å…¥SNNé€‚é…å™¨
    """
    
    def __init__(self, pretrain_path, snn_layer_indices=None, msf_config=None):
        super().__init__()
        
        # 1. åŠ è½½åŸå§‹é¢„è®­ç»ƒæ¨¡å‹ï¼ˆç»“æ„ä¸å˜ï¼‰
        self.model = Qwen2ForCausalLM.from_pretrained(pretrain_path)
        self.config = self.model.config
        
        # 2. MSFé…ç½®
        self.msf_config = msf_config or {
            'decay': 0.25,
            'init_thre': 1.0,
            'D': 4,
            'surro_gate': 'rectangular',
            'use_projection': False
        }
        
        # 3. ç¡®å®šå“ªäº›å±‚æ·»åŠ SNNé€‚é…å™¨
        if snn_layer_indices is None:
            # é»˜è®¤ï¼šä¸­é—´1/3çš„å±‚ä½¿ç”¨SNN
            num_layers = len(self.model.model.layers)
            start_idx = num_layers // 3
            end_idx = start_idx + num_layers // 3
            self.snn_layer_indices = list(range(start_idx, end_idx))
        else:
            self.snn_layer_indices = snn_layer_indices
            
        # 4. ä¸ºæŒ‡å®šå±‚åˆ›å»ºSNNé€‚é…å™¨
        self.snn_adapters = nn.ModuleDict()
        for layer_idx in self.snn_layer_indices:
            self.snn_adapters[str(layer_idx)] = SNNAdapter(
                self.config.hidden_size, 
                self.msf_config
            )
            
        print(f"ğŸ§  SNNé€‚é…å™¨å·²æ·»åŠ åˆ°å±‚: {self.snn_layer_indices}")
        print(f"ğŸ“¦ é¢„è®­ç»ƒæƒé‡ä¿æŒå®Œæ•´ï¼ŒSNNé€‚é…å™¨ä»é›¶å¼€å§‹è®­ç»ƒ")
    
    def forward(self, xs: torch.Tensor, xs_lens: torch.Tensor):
        B, T = xs.size(0), xs.size(1)
        masks = ~make_pad_mask(xs_lens, T)  # [B, T] bool
        
        # åˆ›å»ºcausal maskå¹¶æ‰©å±•åˆ°batch size
        causal_mask = torch.tril(torch.ones((T, T), device=xs.device)).bool()
        attention_mask = causal_mask.unsqueeze(0).unsqueeze(1).expand(B, 1, T, T)  # [B, 1, T, T]
        
        # é€å±‚å‰å‘ä¼ æ’­
        hidden_states = xs
        
        for layer_idx, layer in enumerate(self.model.model.layers):
            # æ ‡å‡†Transformerå±‚å‰å‘
            hidden_states = layer(hidden_states, attention_mask=attention_mask)[0]
            
            # å¦‚æœè¯¥å±‚æœ‰SNNé€‚é…å™¨ï¼Œåˆ™è¿›è¡ŒSNNå¢å¼º
            if layer_idx in self.snn_layer_indices:
                snn_adapter = self.snn_adapters[str(layer_idx)]
                hidden_states = snn_adapter(hidden_states)
                
        return hidden_states, masks.unsqueeze(1)
    
    def forward_one_step(self, xs: torch.Tensor, masks=None, cache=None):
        """å•æ­¥æ¨ç† - éœ€è¦å¤„ç†SNNé€‚é…å™¨çš„çŠ¶æ€"""
        hidden_states = xs
        new_cache = []
        
        for layer_idx, layer in enumerate(self.model.model.layers):
            past_kv = cache[layer_idx] if cache is not None else None
            
            # å¤„ç†attention mask
            attention_mask = None
            if masks is not None:
                # masks shape is [batch, seq_len, seq_len], need to expand for attention
                attention_mask = masks
            
            # æ ‡å‡†å±‚å‰å‘
            layer_outputs = layer(
                hidden_states,
                attention_mask=attention_mask,
                past_key_value=past_kv,
                use_cache=True
            )
            hidden_states = layer_outputs[0]
            new_cache.append(layer_outputs[1] if len(layer_outputs) > 1 else None)
            
            # SNNå¢å¼ºï¼ˆå•æ­¥æ¨ç†æ—¶éœ€è¦å°å¿ƒå¤„ç†ï¼‰
            if layer_idx in self.snn_layer_indices:
                snn_adapter = self.snn_adapters[str(layer_idx)]
                hidden_states = snn_adapter(hidden_states)
        
        return hidden_states, new_cache
    
    def get_snn_strength(self):
        """è·å–å½“å‰SNNé€‚é…å™¨çš„å½±å“å¼ºåº¦"""
        strengths = {}
        for layer_idx in self.snn_layer_indices:
            alpha = self.snn_adapters[str(layer_idx)].alpha.item()
            strengths[layer_idx] = alpha
        return strengths
    
    def set_snn_strength(self, alpha_value):
        """è®¾ç½®æ‰€æœ‰SNNé€‚é…å™¨çš„å½±å“å¼ºåº¦"""
        for layer_idx in self.snn_layer_indices:
            self.snn_adapters[str(layer_idx)].alpha.data.fill_(alpha_value)
    
    def freeze_pretrained_weights(self):
        """å†»ç»“é¢„è®­ç»ƒæƒé‡ï¼Œåªè®­ç»ƒSNNé€‚é…å™¨"""
        # å†»ç»“åŸå§‹æ¨¡å‹æƒé‡
        for param in self.model.parameters():
            param.requires_grad = False
        
        # è§£å†»SNNé€‚é…å™¨æƒé‡    
        for adapter in self.snn_adapters.values():
            for param in adapter.parameters():
                param.requires_grad = True
                
        print("ğŸ”’ é¢„è®­ç»ƒæƒé‡å·²å†»ç»“ï¼Œåªæœ‰SNNé€‚é…å™¨å¯è®­ç»ƒ")
    
    def unfreeze_all_weights(self):
        """è§£å†»æ‰€æœ‰æƒé‡ï¼Œè¿›è¡Œç«¯åˆ°ç«¯å¾®è°ƒ"""
        for param in self.parameters():
            param.requires_grad = True
        print("ğŸ”“ æ‰€æœ‰æƒé‡å·²è§£å†»ï¼Œå¯è¿›è¡Œç«¯åˆ°ç«¯è®­ç»ƒ")


class Qwen2LM_SNN(Qwen2LM):
    """å…¼å®¹é¢„è®­ç»ƒæƒé‡çš„SNNå¢å¼ºQwen2è¯­è¨€æ¨¡å‹"""
    
    def __init__(
        self,
        llm_input_size: int,
        llm_output_size: int,
        speech_token_size: int,
        llm: Qwen2Encoder_SNN,  # æ³¨æ„è¿™é‡Œæ˜¯æ–°çš„ç¼–ç å™¨
        sampling: Callable,
        length_normalized_loss: bool = True,
        lsm_weight: float = 0.0,
        mix_ratio: List[int] = [5, 15],
        training_mode: str = 'snn_only',  # 'snn_only', 'end_to_end', 'gradual'
    ):
        super().__init__(
            llm_input_size=llm_input_size,
            llm_output_size=llm_output_size,
            speech_token_size=speech_token_size,
            llm=llm,
            sampling=sampling,
            length_normalized_loss=length_normalized_loss,
            lsm_weight=lsm_weight,
            mix_ratio=mix_ratio
        )
        
        self.training_mode = training_mode
        self._setup_training_mode()
        
        print(f"ğŸ¯ SNN-LLMå…¼å®¹æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
        print(f"   - è®­ç»ƒæ¨¡å¼: {training_mode}")
        print(f"   - SNNå±‚ä½ç½®: {llm.snn_layer_indices}")
        print(f"   - é¢„è®­ç»ƒæƒé‡: å®Œå…¨ä¿ç•™")
    
    def _setup_training_mode(self):
        """æ ¹æ®è®­ç»ƒæ¨¡å¼è®¾ç½®æƒé‡å†»ç»“çŠ¶æ€"""
        if self.training_mode == 'snn_only':
            # åªè®­ç»ƒSNNé€‚é…å™¨
            self.llm.freeze_pretrained_weights()
        elif self.training_mode == 'end_to_end':
            # ç«¯åˆ°ç«¯è®­ç»ƒ
            self.llm.unfreeze_all_weights()
        elif self.training_mode == 'gradual':
            # æ¸è¿›è®­ç»ƒï¼šå…ˆå†»ç»“ï¼Œåé¢å¯ä»¥è§£å†»
            self.llm.freeze_pretrained_weights()
    
    def set_training_mode(self, mode: str):
        """åŠ¨æ€åˆ‡æ¢è®­ç»ƒæ¨¡å¼"""
        self.training_mode = mode
        self._setup_training_mode()
        print(f"ğŸ”„ è®­ç»ƒæ¨¡å¼å·²åˆ‡æ¢ä¸º: {mode}")
    
    def get_training_status(self):
        """è·å–å½“å‰è®­ç»ƒçŠ¶æ€"""
        total_params = sum(p.numel() for p in self.parameters())
        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
        snn_strengths = self.llm.get_snn_strength()
        
        return {
            'training_mode': self.training_mode,
            'total_params': total_params,
            'trainable_params': trainable_params,
            'trainable_ratio': trainable_params / total_params,
            'snn_strengths': snn_strengths
        }
    
    def forward(self, batch: dict, device: torch.device):
        """å‰å‘ä¼ æ’­ - ä¸åŸç‰ˆå®Œå…¨å…¼å®¹"""
        return super().forward(batch, device)
    
    @torch.inference_mode()
    def inference(self, *args, **kwargs):
        """æ¨ç† - ä¸åŸç‰ˆå®Œå…¨å…¼å®¹"""
        return super().inference(*args, **kwargs)
    
    def progressive_training_schedule(self, epoch: int, total_epochs: int):
        """æ¸è¿›å¼è®­ç»ƒè°ƒåº¦"""
        if self.training_mode == 'gradual':
            # å‰50%è®­ç»ƒå‘¨æœŸåªè®­ç»ƒSNNé€‚é…å™¨
            if epoch < total_epochs * 0.5:
                self.llm.freeze_pretrained_weights()
                # é€æ¸å¢åŠ SNNå¼ºåº¦
                alpha = min(0.5, epoch / (total_epochs * 0.3))
                self.llm.set_snn_strength(alpha)
            else:
                # å50%è§£å†»æ‰€æœ‰æƒé‡ï¼Œè¿›è¡Œç«¯åˆ°ç«¯å¾®è°ƒ
                self.llm.unfreeze_all_weights()
                # SNNå¼ºåº¦ä¿æŒç¨³å®š
                self.llm.set_snn_strength(0.3)