# Improved SNN-Enhanced CosyVoice
# é’ˆå¯¹è®­ç»ƒç¨³å®šæ€§å’Œæ•ˆæœçš„æ”¹è¿›ç‰ˆæœ¬

import torch
import torch.nn as nn
from transformers import Qwen2ForCausalLM
from cosyvoice.utils.mask import make_pad_mask
from cosyvoice.llm.llm import Qwen2LM


class StabilizedSNNAdapter(nn.Module):
    """
    ç¨³å®šåŒ–çš„SNNé€‚é…å™¨ - è§£å†³è®­ç»ƒä¸ç¨³å®šé—®é¢˜
    """
    
    def __init__(self, hidden_size, msf_config):
        super().__init__()
        from cosyvoice.snn.modules import mem_update_MSF
        
        # SNNå¤„ç†å™¨
        self.snn_processor = mem_update_MSF(
            decay=msf_config.get('decay', 0.25),
            init_thre=msf_config.get('init_thre', 1.0),
            D=msf_config.get('D', 4),
            surro_gate=msf_config.get('surro_gate', 'rectangular')
        )
        
        # å…³é”®æ”¹è¿›1: æ¢¯åº¦ç¼©æ”¾å™¨ï¼ˆå¢åŠ åˆå§‹å€¼ç¡®ä¿æœ‰æ•ˆæ¢¯åº¦ä¼ æ’­ï¼‰
        self.grad_scale = nn.Parameter(torch.tensor(0.5))
        
        # å…³é”®æ”¹è¿›2: è‡ªé€‚åº”èåˆæƒé‡ï¼ˆä»é€‚ä¸­å€¼å¼€å§‹ï¼Œç¡®ä¿æ¢¯åº¦æµï¼‰
        self.alpha = nn.Parameter(torch.tensor(0.1))  # å¢åŠ åˆå§‹å€¼ï¼Œç¡®ä¿æœ‰æ•ˆçš„æ¢¯åº¦æµ
        
        # å…³é”®æ”¹è¿›3: é¢„å¤„ç†å±‚ï¼ˆå‡å°‘è¾“å…¥å¹…åº¦ï¼‰  
        self.input_norm = nn.LayerNorm(hidden_size)
        self.pre_proj = nn.Linear(hidden_size, hidden_size)
        
        # å…³é”®æ”¹è¿›4: åå¤„ç†å±‚ï¼ˆç¨³å®šè¾“å‡ºï¼‰
        self.post_norm = nn.LayerNorm(hidden_size) 
        self.post_proj = nn.Linear(hidden_size, hidden_size)
        
        # å…³é”®æ”¹è¿›5: Dropouté˜²æ­¢è¿‡æ‹Ÿåˆ
        self.dropout = nn.Dropout(0.1)
        
        # åˆå§‹åŒ–æƒé‡
        self._init_weights()
        
    def _init_weights(self):
        """æ›´ç§¯æçš„æƒé‡åˆå§‹åŒ–ï¼Œç¡®ä¿æ¢¯åº¦æµ"""
        nn.init.xavier_uniform_(self.pre_proj.weight, gain=0.5)  # å¢åŠ gainå€¼
        nn.init.xavier_uniform_(self.post_proj.weight, gain=0.5)  # å¢åŠ gainå€¼
        nn.init.zeros_(self.pre_proj.bias)
        nn.init.zeros_(self.post_proj.bias)
    
    def forward(self, x):
        """
        x: [batch, seq_len, hidden_size]
        """
        batch_size, seq_len, hidden_size = x.shape
        
        # 1. è¾“å…¥é¢„å¤„ç†å’Œå½’ä¸€åŒ–
        x_norm = self.input_norm(x)
        x_proj = self.pre_proj(x_norm)
        
        # 2. SNNå¤„ç†ï¼ˆè¾“å…¥æ ¼å¼è½¬æ¢ï¼‰
        snn_input = x_proj.permute(1, 0, 2)  # [seq_len, batch, hidden_size]
        
        # å…³é”®æ”¹è¿›: æ¢¯åº¦è£å‰ªä¿æŠ¤ï¼ˆæ”¾æ¾è£å‰ªé˜ˆå€¼ï¼‰
        with torch.no_grad():
            input_norm = torch.norm(snn_input)
            if input_norm > 50.0:  # æé«˜é˜ˆå€¼ï¼Œå‡å°‘è¿‡åº¦è£å‰ª
                snn_input = snn_input * (50.0 / input_norm)
        
        snn_output = self.snn_processor(snn_input)  
        snn_output = snn_output.permute(1, 0, 2)  # è½¬å› [batch, seq_len, hidden_size]
        
        # 3. åå¤„ç†å’Œå½’ä¸€åŒ–
        snn_output = self.post_norm(snn_output)
        snn_output = self.post_proj(snn_output)
        snn_output = self.dropout(snn_output)
        
        # 4. æ”¹è¿›çš„æ®‹å·®è¿æ¥ï¼ˆç¡®ä¿æœ‰æ•ˆçš„æ¢¯åº¦æµï¼‰
        alpha_clamped = torch.clamp(self.alpha, 0.0, 0.5)  # æé«˜ä¸Šé™ï¼Œå…è®¸æ›´å¼ºçš„èåˆ
        grad_scale_clamped = torch.clamp(self.grad_scale, 0.1, 1.0)  # ç¡®ä¿æ¢¯åº¦ç¼©æ”¾æœ‰æ•ˆ
        enhanced_output = x + alpha_clamped * snn_output * grad_scale_clamped
        
        return enhanced_output
    
    def get_fusion_weight(self):
        """è¿”å›å½“å‰èåˆæƒé‡ï¼Œç”¨äºç›‘æ§"""
        return torch.clamp(self.alpha, 0.0, 0.5).item()


class Qwen2Encoder_SNN_Improved(nn.Module):
    """
    æ”¹è¿›ç‰ˆSNNå¢å¼ºQwen2ç¼–ç å™¨ - æ³¨é‡è®­ç»ƒç¨³å®šæ€§
    """
    
    def __init__(self, pretrain_path, snn_layer_indices=None, msf_config=None):
        super().__init__()
        
        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        self.model = Qwen2ForCausalLM.from_pretrained(pretrain_path)
        
        # SNNé…ç½®
        self.snn_layer_indices = snn_layer_indices or [10, 11, 12, 13]
        msf_config = msf_config or {}
        
        # åˆ›å»ºç¨³å®šåŒ–SNNé€‚é…å™¨
        self.snn_adapters = nn.ModuleDict()
        for layer_idx in self.snn_layer_indices:
            if layer_idx < len(self.model.model.layers):
                adapter = StabilizedSNNAdapter(
                    hidden_size=self.model.config.hidden_size,
                    msf_config=msf_config
                )
                self.snn_adapters[str(layer_idx)] = adapter
        
        print(f"ğŸ§  æ”¹è¿›ç‰ˆ: ç¨³å®šåŒ–SNNé€‚é…å™¨å·²æ·»åŠ åˆ°å±‚: {self.snn_layer_indices}")
        print(f"ğŸ“ˆ ä½¿ç”¨æ¢¯åº¦ç¼©æ”¾ã€æƒé‡è£å‰ªå’Œä¿å®ˆèåˆç­–ç•¥")
        
    def freeze_pretrained_weights(self):
        """å†»ç»“é¢„è®­ç»ƒæƒé‡ï¼Œåªè®­ç»ƒSNNç»„ä»¶"""
        frozen_params = 0
        snn_params = 0
        
        for name, param in self.named_parameters():
            if any(snn_name in name for snn_name in ['snn_adapters', 'alpha', 'grad_scale', 'pre_proj', 'post_proj']):
                param.requires_grad = True
                snn_params += param.numel()
            else:
                param.requires_grad = False
                frozen_params += param.numel()
        
        print(f"ğŸ”’ æ”¹è¿›ç‰ˆ: é¢„è®­ç»ƒæƒé‡å·²å†»ç»“: {frozen_params:,} å‚æ•°")
        print(f"ğŸ¯ SNNå¯è®­ç»ƒå‚æ•°: {snn_params:,} å‚æ•°")
        return snn_params, frozen_params
    
    def forward(self, xs: torch.Tensor, xs_lens: torch.Tensor):
        B, T = xs.size(0), xs.size(1)
        masks = ~make_pad_mask(xs_lens, T)  # [B, T] bool
        
        # åˆ›å»ºcausal maskå¹¶æ‰©å±•åˆ°batch size
        causal_mask = torch.tril(torch.ones((T, T), device=xs.device)).bool()
        attention_mask = causal_mask.unsqueeze(0).unsqueeze(1).expand(B, 1, T, T)
        
        # é€å±‚å‰å‘ä¼ æ’­
        hidden_states = xs
        
        for layer_idx, layer in enumerate(self.model.model.layers):
            # æ ‡å‡†Transformerå±‚å‰å‘
            hidden_states = layer(hidden_states, attention_mask=attention_mask)[0]
            
            # å¦‚æœè¯¥å±‚æœ‰SNNé€‚é…å™¨ï¼Œåˆ™è¿›è¡ŒSNNå¢å¼º
            if layer_idx in self.snn_layer_indices:
                snn_adapter = self.snn_adapters[str(layer_idx)]
                
                # å…³é”®æ”¹è¿›: è¾“å…¥æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥
                if self.training:
                    with torch.no_grad():
                        # æ£€æŸ¥è¾“å…¥çš„æ•°å€¼ç¨³å®šæ€§è€Œä¸æ˜¯æ¢¯åº¦
                        input_norm = torch.norm(hidden_states)
                        if torch.isnan(input_norm) or torch.isinf(input_norm) or input_norm > 100.0:
                            # å¦‚æœè¾“å…¥ä¸ç¨³å®šï¼Œè·³è¿‡SNNå¤„ç†
                            continue
                
                hidden_states = snn_adapter(hidden_states)
                
        return hidden_states, masks.unsqueeze(1)
    
    def forward_one_step(self, xs, masks, cache=None):
        """Single-step forward for inference with caching"""
        input_masks = masks[:, -1, :]
        outs = self.model(
            inputs_embeds=xs,
            attention_mask=input_masks,
            output_hidden_states=True,
            return_dict=True,
            use_cache=True,
            past_key_values=cache,
        )
        xs = outs.hidden_states[-1]
        new_cache = outs.past_key_values
        return xs, new_cache
    
    def get_training_status(self):
        """è¿”å›è®­ç»ƒçŠ¶æ€ä¿¡æ¯"""
        total_params = sum(p.numel() for p in self.parameters())
        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
        
        # æ”¶é›†SNNé€‚é…å™¨çŠ¶æ€
        snn_weights = {}
        for idx, adapter in self.snn_adapters.items():
            snn_weights[idx] = adapter.get_fusion_weight()
        
        return {
            'training_mode': 'snn_improved',
            'total_params': total_params,
            'trainable_params': trainable_params,
            'trainable_ratio': trainable_params / total_params,
            'snn_weights': snn_weights
        }


class Qwen2LM_SNN_Improved(Qwen2LM):
    """
    æ”¹è¿›ç‰ˆSNNå¢å¼ºçš„Qwen2è¯­è¨€æ¨¡å‹ - ç¨³å®šè®­ç»ƒç‰ˆæœ¬
    """
    
    def __init__(self, llm_input_size, llm_output_size, speech_token_size, 
                 length_normalized_loss=True, lsm_weight=0, mix_ratio=[5, 15],
                 training_mode='snn_only', llm=None, sampling=None):
        
        # ä½¿ç”¨æ”¹è¿›çš„SNNç¼–ç å™¨
        if llm is None:
            llm = Qwen2Encoder_SNN_Improved(
                pretrain_path='',  # ä¼šåœ¨é…ç½®ä¸­æŒ‡å®š
                snn_layer_indices=[10, 11, 12, 13],
                msf_config={'decay': 0.25, 'init_thre': 1.0, 'D': 4}
            )
        
        super().__init__(
            llm_input_size=llm_input_size,
            llm_output_size=llm_output_size, 
            speech_token_size=speech_token_size,
            length_normalized_loss=length_normalized_loss,
            lsm_weight=lsm_weight,
            mix_ratio=mix_ratio,
            llm=llm,
            sampling=sampling
        )
        
        self.training_mode = training_mode
        
        # æ ¹æ®è®­ç»ƒæ¨¡å¼è®¾ç½®å‚æ•°æ¢¯åº¦
        if training_mode == 'snn_only':
            self.llm.freeze_pretrained_weights()
            print(f"ğŸ¯ æ”¹è¿›ç‰ˆ: SNN-onlyç¨³å®šè®­ç»ƒæ¨¡å¼")
        else:
            print(f"ğŸ”„ æ”¹è¿›ç‰ˆ: {training_mode}è®­ç»ƒæ¨¡å¼")
    
    def get_training_status(self):
        """è·å–è®­ç»ƒçŠ¶æ€"""
        return self.llm.get_training_status()